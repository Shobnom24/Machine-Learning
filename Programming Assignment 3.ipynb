{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DwD0AKrBChEt"
   },
   "source": [
    "Please read the documentation for [transforms](https://pytorch.org/vision/0.12/transforms.html) and [CIFAR-10](https://pytorch.org/vision/stable/generated/torchvision.datasets.CIFAR10.html#torchvision.datasets.CIFAR10) before starting your programming. \n",
    "\n",
    "## **Question 1**: Read the 'transform' documentation and describe as why we are adding the follwoing line:(10 Pts)\n",
    "***'transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])'***\n",
    "\n",
    "## **Question 2**: What is CIFAR10 dataset, input dimensions, output classes (labels) and size of dataset (10 Pts)\n",
    "\n",
    "## **Question 3**: add your training/validation loss figure here and describe why you are encountering underfitting and overfitting issue (10 Pts)\n",
    "\n",
    "## **Question 4**: update your model to address the underfit and overfit issue and add your new training/validation loss figure here (15 Pts)\n",
    "\n",
    "## **Question 5**: update your DataLoader and entire code to incldue k-fold training, valiation, and testing (15 Pts)\n",
    "\n",
    "## **Question 6**: change the learning rate to 0.5, 0.1, 0.01,0.001 and retrain the model, describe the result and attached each graph. (20 Pts) \n",
    "\n",
    "## **Question 7**: Define a new model call Net_2 wihtout hidden layer or activation function, what is your observation during training loop and why? (20)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-OpVzrovCnCX"
   },
   "source": [
    "# Training Neural Networks\n",
    "In Assignment 3 Programming, you will train a neural network using PyTorch.  \n",
    "\n",
    "This will walk through the entire process, from loading datasets, creating the network code and training it to classify the CIFAR-10 dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Aa5j83qBCpye"
   },
   "outputs": [],
   "source": [
    "# Import Prebuild Python Packages and Modules \n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision import datasets\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZD1M-muXDW9L"
   },
   "source": [
    "## Loading and *Preprocessing* Data using DataLoader\n",
    "you will load and preprocess our input and label data using methods from `datasets` and `transforms`.\n",
    "\n",
    "Then, we will create `DataLoader`s for our train and validation test sets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "30-8mSt6DZre",
    "outputId": "78b6bc35-b4cc-4c06-d5a6-c269c3cfdd6c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Establish our transform\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "# Load train and test CIFAR10 datasets\n",
    "training_data = datasets.CIFAR10(root=\"data\", train=True, download=True, transform=transform)\n",
    "validation_data = datasets.CIFAR10(root=\"data\", train=False, download=True, transform=transform)\n",
    "\n",
    "# Create the training and test dataloaders with a batch size of 32\n",
    "train_loader = DataLoader(training_data, batch_size=32, shuffle=True)\n",
    "validation_loader = DataLoader(validation_data, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2TQAtBluQWhP"
   },
   "source": [
    "## Defining your Neural Network\n",
    "Now you are ready to define your model. Since you are using Deep Neural Network architecutre and your input image has three dimentions, first you need to flatten your input into a single input. \n",
    "\n",
    "Feel free to experiment here, and if you need additional help, consult the [PyTorch documentation](https://pytorch.org/docs/stable/nn.html)\n",
    "\n",
    "Add two hidden layers:\n",
    "- hidden layer 1 = 120 neurons\n",
    "- hiddel layer 2 = 84 neurons\n",
    "- use relu ONLY at the end of both hidden layers \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Jql5JP4kQXuF"
   },
   "outputs": [],
   "source": [
    "# Define the class for your neural network in this cell\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        ##### add your code here\n",
    "        \n",
    "    def forward(self, x):\n",
    "        ##### add your code here\n",
    "        return x\n",
    "\n",
    "# Instantiate the model\n",
    "net = Net()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F1NjdfPKRqBa"
   },
   "source": [
    "## Optimizer and Loss function\n",
    "Before you get into our training loop, you need to choose an optimizer and loss function for our network training. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9qFIzDPgR0k6"
   },
   "outputs": [],
   "source": [
    "# Choose an optimizer\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "\n",
    "# Choose a loss function \n",
    "criterion = ##### add your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KzPzv9aqSvqB"
   },
   "source": [
    "## Creating the Training Loop\n",
    "With you network, optimizer, and loss function, now you can begin the training step (uptimizing the weight values) \n",
    "Using the validation set to validate your accuracy, you can see when our network has given you the best fit and avoid overfit or underfit senarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RuCOChvKTZic"
   },
   "outputs": [],
   "source": [
    "num_epochs = 10\n",
    "\n",
    "# Establish a list for your loss history\n",
    "train_loss_history = list()\n",
    "validation_loss_history = list()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    net.train()\n",
    "    train_loss = 0.0\n",
    "    train_correct = 0\n",
    "    ## for each data batch \n",
    "    for i, data in enumerate(train_loader):\n",
    "        # data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "\n",
    "        # Pass to GPU if available.\n",
    "        if torch.cuda.is_available():\n",
    "            inputs, labels = inputs.cuda(), labels.cuda()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        _, preds = torch.max(outputs.data, 1)\n",
    "        train_correct += (preds == labels).sum().item()\n",
    "        train_loss += loss.item()\n",
    "    print(f'Epoch {epoch + 1} training accuracy: {train_correct/len(train_loader):.2f}% training loss: {train_loss/len(train_loader):.5f}')\n",
    "    train_loss_history.append(train_loss/len(train_loader))\n",
    "\n",
    "\n",
    "    validation_loss = 0.0\n",
    "    validation_correct = 0\n",
    "    net.eval()\n",
    "    for inputs, labels in validation_loader:\n",
    "        if torch.cuda.is_available():\n",
    "            inputs, labels = inputs.cuda(), labels.cuda()\n",
    "\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        _, preds = torch.max(outputs.data, 1)\n",
    "        validation_correct += (preds == labels).sum().item()\n",
    "        validation_loss += loss.item()\n",
    "    print(f'Epoch {epoch + 1} validation accuracy: {validation_correct/len(validation_loader):.2f}% validation loss: {validation_loss/len(validation_loader):.5f}')\n",
    "    validation_loss_history.append(validation_loss/len(validation_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F3yRCqzmU96E"
   },
   "outputs": [],
   "source": [
    "# Plot the training and validation loss history\n",
    "plt.plot(train_loss_history, label=\"Training Loss\")\n",
    "plt.plot(validation_loss_history, label=\"Validation Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
